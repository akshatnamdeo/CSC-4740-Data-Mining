# Predictability and Variability in Adverse Event Reporting  
### A Multi-Task Machine Learning Analysis

This repository contains the code, notebooks, and figures associated with the project  
**“Predictability and Variability in Adverse Event Reporting: A Multi-Task Machine Learning Analysis.”**

The goal of this project is not to maximize predictive performance, but to analyze **what aspects of spontaneous adverse event data are predictable**, which are not, and why. We use multiple machine learning tasks over the same FAERS-based dataset to probe structure, noise, and variability in adverse event reporting.

---

## Project Overview and Goals

Spontaneous reporting systems such as FAERS are widely used for post-marketing drug surveillance, but they are known to be heterogeneous, incomplete, and biased. In this project, we treat machine learning as a **diagnostic tool** rather than a purely predictive one.

Specifically, we study three complementary tasks:

1. **Event Count Regression**  
   To assess whether total adverse event burden is a well-posed prediction target.

2. **Severity Classification**  
   To evaluate whether maximum reported severity exhibits learnable structure beyond reporting noise.

3. **Multi-Label Physiological System Prediction**  
   To examine system-level toxicity patterns and label co-occurrence under extreme class imbalance.

Across all tasks, the emphasis is on interpretation, error analysis, and understanding the limits of predictability in real-world pharmacovigilance data.

---

### Notebooks

- **Stage 1 - Preprocessing.ipynb**  
  Performs data normalization, filtering, and integration across FAERS, FDA drug metadata, PharmGKB, and GTEx.  
  This notebook requires **raw source datasets**, which cannot be redistributed. See *Data Availability* below.

- **Model1.ipynb**  
  Event count regression using tree-based models. Focuses on error structure, residual behavior, and predictability limits rather than point accuracy.

- **Model2.ipynb**  
  Multiclass severity classification after removal of the dominant `unknown` label. Includes baseline comparisons and feature importance analysis.

- **Model3.ipynb**  
  Multi-label physiological system prediction. Evaluates linear baselines, neural models, and class-specific threshold tuning under severe label imbalance.

Each model notebook is designed to run **end-to-end**, assuming the processed data folder is available.

---

## Figures

All figures included in the repository are generated by the notebooks and correspond directly to analyses reported in the paper. They illustrate distributions, stratifications, feature importance, and error behavior across tasks. No additional manual post-processing was applied.

---

## Data Availability

### Processed Data (Required to Run Model Notebooks)

To run **Model1.ipynb**, **Model2.ipynb**, and **Model3.ipynb**, a folder named `data/` must be placed in the repository root.

A compressed archive containing this folder is available here:

**Data folder (data.zip)**  
https://drive.google.com/drive/folders/1P-fX4fNanFaYZc_wSJ495-AOulLnkdqS?usp=sharing

---

### Raw Data and Preprocessing

The **Stage 1 - Preprocessing.ipynb** notebook requires raw datasets from:

- FDA Adverse Event Reporting System (FAERS)
- FDA Drug & Regulatory Data
- PharmGKB
- GTEx (v10)

Due to size and licensing constraints, these raw datasets are **not redistributed**. The preprocessing notebook documents how these sources are combined and normalized.

---

## Reproducibility Status

At present, the notebooks are intended for **analysis and inspection**, not strict bitwise reproducibility.  
Sources of non-determinism include:

- Random initialization in models
- GPU-accelerated training
- Streaming batch order

We plan to add:
- Fixed random seeds
- Environment specifications
- Reproducibility scripts

in a future update.

---

## Requirements

The notebooks assume a standard Python data science stack, including (but not limited to):

- Python 3.9+
- pandas
- numpy
- scikit-learn
- catboost
- torch
- shap
- matplotlib / seaborn

Exact versions are not pinned yet.

---

## Notes

- This project emphasizes **interpretation over optimization**.
- Results should be interpreted as characterizing structure and variability in reporting data, not as clinical predictions.
- Genetic and biological features are included as contextual signals, not causal claims.

---

## Authors

- Akshat Namdeo  
- Kartikeya Duvvuri  
- Sree Yashas Kuchi  

Department of Computer Science  
Georgia State University

---

## License

This repository is intended for academic and educational use.
